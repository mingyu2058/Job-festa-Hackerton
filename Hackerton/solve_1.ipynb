{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bbf86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e091fc",
   "metadata": {},
   "source": [
    "## Importing and Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf6b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_df = pd.read_csv('./1번/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f8e18",
   "metadata": {},
   "source": [
    "## Visualising Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a0a907",
   "metadata": {},
   "source": [
    "## Correlation Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bede4d",
   "metadata": {},
   "source": [
    "## Splitting Train/Test set(컬럼 8, 11 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fb52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature variable to X\n",
    "X = fuel_df[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "       'feature_5', 'feature_6', 'feature_7','feature_9',\n",
    "       'feature_10', 'feature_12', 'feature_13', 'feature_14']]\n",
    "\n",
    "# response target variable to y\n",
    "y = fuel_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166c0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7 , random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ce3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier(df=None, column=None, weight=1.5):\n",
    "  # target 값과 상관관계가 높은 열을 우선적으로 진행\n",
    "  quantile_25 = np.percentile(df[column].values, 25)\n",
    "  quantile_75 = np.percentile(df[column].values, 75)\n",
    "\n",
    "  IQR = quantile_75 - quantile_25\n",
    "  IQR_weight = IQR*weight\n",
    "  \n",
    "  lowest = quantile_25 - IQR_weight\n",
    "  highest = quantile_75 + IQR_weight\n",
    "  \n",
    "  outlier_idx = df[column][ (df[column] < lowest) | (df[column] > highest) ].index\n",
    "  return outlier_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09da9a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_idx = get_outlier(df=fuel_df, column='feature_4', weight=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02566765",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_df.drop(outlier_idx, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00616027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "X_train = np.log1p(X_train)\n",
    "#X_test = np.log1p(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e4a1d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minMaxScaler = MinMaxScaler()\n",
    "print(minMaxScaler.fit(X_train))\n",
    "X_train = minMaxScaler.transform(X_train)\n",
    "#X_test = minMaxScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cbf34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardScaler = StandardScaler()\n",
    "\n",
    "print(standardScaler.fit(X_train))\n",
    "X_train = standardScaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a53398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "#X_train = np.log1p(X_train)\n",
    "#X_test = np.log1p(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55301dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "robustScaler = RobustScaler()\n",
    "print(robustScaler.fit(X_train))\n",
    "X_train = robustScaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12b07b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c57c0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beaef82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_input=1):\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(8912, activation='relu',input_dim=num_input))\n",
    "    #model.add(Dense(4096, activation='relu'))\n",
    "    #model.add(Dense(2048, activation='relu'))\n",
    "    #model.add(Dense(1024, activation='relu',input_dim=num_input))\n",
    "    #model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu',input_dim=num_input))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    #model.add(Dense(100, activation='relu',input_dim=num_input))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='SGD', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#otms = optimizers.SGD(learning_rate=0.01)\n",
    "#otms = optimizers.Adagrad(learning_rate=0.01) # okay\n",
    "#otms = optimizers.Adamax(learning_rate=0.01) # okay\n",
    "#otms = optimizers.Ftrl(learning_rate=0.01) # okay\n",
    "#otms = optimizers.Nadam(learning_rate=0.01) # okay\n",
    "#otms = optimizers.RMSprop(learning_rate=0.01) # problem\n",
    "\n",
    "#model.compile(optimizer=otms, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b21a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_input=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac917f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "600/600 [==============================] - 0s 734us/step - loss: 1.1184e-07 - mae: 2.7871e-04\n",
      "Epoch 2/300\n",
      "600/600 [==============================] - 0s 801us/step - loss: 1.1184e-07 - mae: 2.7870e-04\n",
      "Epoch 3/300\n",
      "600/600 [==============================] - 0s 741us/step - loss: 1.1183e-07 - mae: 2.7870e-04\n",
      "Epoch 4/300\n",
      "600/600 [==============================] - 0s 744us/step - loss: 1.1182e-07 - mae: 2.7868e-04\n",
      "Epoch 5/300\n",
      "600/600 [==============================] - 0s 755us/step - loss: 1.1182e-07 - mae: 2.7868e-04\n",
      "Epoch 6/300\n",
      "600/600 [==============================] - 0s 750us/step - loss: 1.1181e-07 - mae: 2.7868e-04\n",
      "Epoch 7/300\n",
      "600/600 [==============================] - 0s 738us/step - loss: 1.1180e-07 - mae: 2.7866e-04\n",
      "Epoch 8/300\n",
      "600/600 [==============================] - 0s 727us/step - loss: 1.1179e-07 - mae: 2.7866e-04\n",
      "Epoch 9/300\n",
      "600/600 [==============================] - 0s 737us/step - loss: 1.1179e-07 - mae: 2.7866e-04\n",
      "Epoch 10/300\n",
      "600/600 [==============================] - 0s 747us/step - loss: 1.1178e-07 - mae: 2.7864e-04\n",
      "Epoch 11/300\n",
      "600/600 [==============================] - 0s 733us/step - loss: 1.1177e-07 - mae: 2.7864e-04\n",
      "Epoch 12/300\n",
      "600/600 [==============================] - 0s 744us/step - loss: 1.1176e-07 - mae: 2.7862e-04\n",
      "Epoch 13/300\n",
      "600/600 [==============================] - 0s 743us/step - loss: 1.1175e-07 - mae: 2.7862e-04\n",
      "Epoch 14/300\n",
      "600/600 [==============================] - 0s 743us/step - loss: 1.1175e-07 - mae: 2.7862e-04\n",
      "Epoch 15/300\n",
      "600/600 [==============================] - 0s 753us/step - loss: 1.1174e-07 - mae: 2.7860e-04\n",
      "Epoch 16/300\n",
      "600/600 [==============================] - 0s 752us/step - loss: 1.1173e-07 - mae: 2.7859e-04\n",
      "Epoch 17/300\n",
      "600/600 [==============================] - 0s 749us/step - loss: 1.1173e-07 - mae: 2.7859e-04\n",
      "Epoch 18/300\n",
      "600/600 [==============================] - 0s 747us/step - loss: 1.1172e-07 - mae: 2.7858e-04\n",
      "Epoch 19/300\n",
      "600/600 [==============================] - 0s 761us/step - loss: 1.1171e-07 - mae: 2.7857e-04\n",
      "Epoch 20/300\n",
      "600/600 [==============================] - 1s 877us/step - loss: 1.1170e-07 - mae: 2.7856e-04\n",
      "Epoch 21/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1169e-07 - mae: 2.7855e-04\n",
      "Epoch 22/300\n",
      "600/600 [==============================] - 1s 927us/step - loss: 1.1169e-07 - mae: 2.7854e-04\n",
      "Epoch 23/300\n",
      "600/600 [==============================] - 0s 768us/step - loss: 1.1168e-07 - mae: 2.7853e-04\n",
      "Epoch 24/300\n",
      "600/600 [==============================] - 0s 789us/step - loss: 1.1167e-07 - mae: 2.7852e-04\n",
      "Epoch 25/300\n",
      "600/600 [==============================] - 0s 819us/step - loss: 1.1167e-07 - mae: 2.7852e-04\n",
      "Epoch 26/300\n",
      "600/600 [==============================] - 0s 724us/step - loss: 1.1166e-07 - mae: 2.7851e-04\n",
      "Epoch 27/300\n",
      "600/600 [==============================] - 0s 781us/step - loss: 1.1165e-07 - mae: 2.7850e-04\n",
      "Epoch 28/300\n",
      "600/600 [==============================] - 0s 781us/step - loss: 1.1165e-07 - mae: 2.7849e-04\n",
      "Epoch 29/300\n",
      "600/600 [==============================] - 0s 717us/step - loss: 1.1164e-07 - mae: 2.7848e-04\n",
      "Epoch 30/300\n",
      "600/600 [==============================] - 0s 704us/step - loss: 1.1163e-07 - mae: 2.7848e-04\n",
      "Epoch 31/300\n",
      "600/600 [==============================] - 0s 729us/step - loss: 1.1162e-07 - mae: 2.7846e-04\n",
      "Epoch 32/300\n",
      "600/600 [==============================] - 0s 708us/step - loss: 1.1161e-07 - mae: 2.7846e-04\n",
      "Epoch 33/300\n",
      "600/600 [==============================] - 0s 703us/step - loss: 1.1160e-07 - mae: 2.7844e-04\n",
      "Epoch 34/300\n",
      "600/600 [==============================] - 0s 807us/step - loss: 1.1160e-07 - mae: 2.7844e-04\n",
      "Epoch 35/300\n",
      "600/600 [==============================] - 0s 796us/step - loss: 1.1159e-07 - mae: 2.7844e-04\n",
      "Epoch 36/300\n",
      "600/600 [==============================] - 0s 766us/step - loss: 1.1159e-07 - mae: 2.7843e-04\n",
      "Epoch 37/300\n",
      "600/600 [==============================] - 0s 736us/step - loss: 1.1158e-07 - mae: 2.7841e-04\n",
      "Epoch 38/300\n",
      "600/600 [==============================] - 0s 738us/step - loss: 1.1157e-07 - mae: 2.7841e-04\n",
      "Epoch 39/300\n",
      "600/600 [==============================] - 0s 736us/step - loss: 1.1157e-07 - mae: 2.7841e-04\n",
      "Epoch 40/300\n",
      "600/600 [==============================] - 0s 741us/step - loss: 1.1156e-07 - mae: 2.7839e-04\n",
      "Epoch 41/300\n",
      "600/600 [==============================] - 0s 713us/step - loss: 1.1155e-07 - mae: 2.7838e-04\n",
      "Epoch 42/300\n",
      "600/600 [==============================] - 0s 722us/step - loss: 1.1154e-07 - mae: 2.7838e-04\n",
      "Epoch 43/300\n",
      "600/600 [==============================] - 0s 727us/step - loss: 1.1154e-07 - mae: 2.7837e-04\n",
      "Epoch 44/300\n",
      "600/600 [==============================] - 0s 728us/step - loss: 1.1153e-07 - mae: 2.7836e-04\n",
      "Epoch 45/300\n",
      "600/600 [==============================] - 0s 753us/step - loss: 1.1152e-07 - mae: 2.7835e-04\n",
      "Epoch 46/300\n",
      "600/600 [==============================] - 0s 721us/step - loss: 1.1151e-07 - mae: 2.7835e-04\n",
      "Epoch 47/300\n",
      "600/600 [==============================] - 0s 727us/step - loss: 1.1151e-07 - mae: 2.7834e-04\n",
      "Epoch 48/300\n",
      "600/600 [==============================] - 0s 734us/step - loss: 1.1150e-07 - mae: 2.7832e-04\n",
      "Epoch 49/300\n",
      "600/600 [==============================] - 0s 708us/step - loss: 1.1149e-07 - mae: 2.7832e-04\n",
      "Epoch 50/300\n",
      "600/600 [==============================] - 0s 721us/step - loss: 1.1149e-07 - mae: 2.7831e-04\n",
      "Epoch 51/300\n",
      "600/600 [==============================] - 0s 735us/step - loss: 1.1148e-07 - mae: 2.7830e-04\n",
      "Epoch 52/300\n",
      "600/600 [==============================] - 0s 730us/step - loss: 1.1147e-07 - mae: 2.7830e-04\n",
      "Epoch 53/300\n",
      "600/600 [==============================] - 0s 709us/step - loss: 1.1146e-07 - mae: 2.7829e-04\n",
      "Epoch 54/300\n",
      "600/600 [==============================] - 0s 753us/step - loss: 1.1146e-07 - mae: 2.7828e-04\n",
      "Epoch 55/300\n",
      "600/600 [==============================] - 0s 679us/step - loss: 1.1145e-07 - mae: 2.7827e-04\n",
      "Epoch 56/300\n",
      "600/600 [==============================] - 0s 724us/step - loss: 1.1144e-07 - mae: 2.7826e-04\n",
      "Epoch 57/300\n",
      "600/600 [==============================] - 0s 814us/step - loss: 1.1143e-07 - mae: 2.7825e-04\n",
      "Epoch 58/300\n",
      "600/600 [==============================] - 0s 773us/step - loss: 1.1143e-07 - mae: 2.7824e-04\n",
      "Epoch 59/300\n",
      "600/600 [==============================] - 1s 922us/step - loss: 1.1142e-07 - mae: 2.7824e-04\n",
      "Epoch 60/300\n",
      "600/600 [==============================] - 1s 860us/step - loss: 1.1142e-07 - mae: 2.7823e-04\n",
      "Epoch 61/300\n",
      "600/600 [==============================] - 1s 953us/step - loss: 1.1141e-07 - mae: 2.7822e-04\n",
      "Epoch 62/300\n",
      "600/600 [==============================] - 1s 974us/step - loss: 1.1140e-07 - mae: 2.7821e-04\n",
      "Epoch 63/300\n",
      "600/600 [==============================] - 1s 841us/step - loss: 1.1139e-07 - mae: 2.7820e-04\n",
      "Epoch 64/300\n",
      "600/600 [==============================] - 0s 745us/step - loss: 1.1139e-07 - mae: 2.7820e-04\n",
      "Epoch 65/300\n",
      "600/600 [==============================] - 0s 758us/step - loss: 1.1138e-07 - mae: 2.7819e-04\n",
      "Epoch 66/300\n",
      "600/600 [==============================] - 0s 741us/step - loss: 1.1137e-07 - mae: 2.7818e-04\n",
      "Epoch 67/300\n",
      "600/600 [==============================] - 0s 752us/step - loss: 1.1136e-07 - mae: 2.7817e-04\n",
      "Epoch 68/300\n",
      "600/600 [==============================] - 0s 747us/step - loss: 1.1136e-07 - mae: 2.7817e-04\n",
      "Epoch 69/300\n",
      "600/600 [==============================] - 0s 799us/step - loss: 1.1135e-07 - mae: 2.7815e-04\n",
      "Epoch 70/300\n",
      "600/600 [==============================] - 0s 778us/step - loss: 1.1134e-07 - mae: 2.7815e-04\n",
      "Epoch 71/300\n",
      "600/600 [==============================] - 0s 741us/step - loss: 1.1133e-07 - mae: 2.7813e-04\n",
      "Epoch 72/300\n",
      "600/600 [==============================] - 0s 746us/step - loss: 1.1133e-07 - mae: 2.7813e-04\n",
      "Epoch 73/300\n",
      "600/600 [==============================] - 0s 743us/step - loss: 1.1132e-07 - mae: 2.7812e-04\n",
      "Epoch 74/300\n",
      "600/600 [==============================] - 0s 743us/step - loss: 1.1131e-07 - mae: 2.7812e-04\n",
      "Epoch 75/300\n",
      "600/600 [==============================] - 0s 749us/step - loss: 1.1131e-07 - mae: 2.7811e-04\n",
      "Epoch 76/300\n",
      "600/600 [==============================] - 0s 763us/step - loss: 1.1130e-07 - mae: 2.7810e-04\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 758us/step - loss: 1.1130e-07 - mae: 2.7810e-04\n",
      "Epoch 78/300\n",
      "600/600 [==============================] - 1s 844us/step - loss: 1.1128e-07 - mae: 2.7808e-04\n",
      "Epoch 79/300\n",
      "600/600 [==============================] - 1s 853us/step - loss: 1.1128e-07 - mae: 2.7808e-04\n",
      "Epoch 80/300\n",
      "600/600 [==============================] - 0s 823us/step - loss: 1.1127e-07 - mae: 2.7807e-04\n",
      "Epoch 81/300\n",
      "600/600 [==============================] - 1s 941us/step - loss: 1.1126e-07 - mae: 2.7806e-04\n",
      "Epoch 82/300\n",
      "600/600 [==============================] - 0s 784us/step - loss: 1.1126e-07 - mae: 2.7806e-04\n",
      "Epoch 83/300\n",
      "600/600 [==============================] - 0s 784us/step - loss: 1.1125e-07 - mae: 2.7805e-04\n",
      "Epoch 84/300\n",
      "600/600 [==============================] - 0s 724us/step - loss: 1.1124e-07 - mae: 2.7804e-04\n",
      "Epoch 85/300\n",
      "600/600 [==============================] - 0s 726us/step - loss: 1.1123e-07 - mae: 2.7803e-04\n",
      "Epoch 86/300\n",
      "600/600 [==============================] - 0s 693us/step - loss: 1.1123e-07 - mae: 2.7803e-04\n",
      "Epoch 87/300\n",
      "600/600 [==============================] - 0s 696us/step - loss: 1.1122e-07 - mae: 2.7802e-04\n",
      "Epoch 88/300\n",
      "600/600 [==============================] - 0s 728us/step - loss: 1.1121e-07 - mae: 2.7801e-04\n",
      "Epoch 89/300\n",
      "600/600 [==============================] - 0s 679us/step - loss: 1.1121e-07 - mae: 2.7800e-04\n",
      "Epoch 90/300\n",
      "600/600 [==============================] - 0s 728us/step - loss: 1.1119e-07 - mae: 2.7800e-04\n",
      "Epoch 91/300\n",
      "600/600 [==============================] - 0s 698us/step - loss: 1.1119e-07 - mae: 2.7799e-04\n",
      "Epoch 92/300\n",
      "600/600 [==============================] - 0s 776us/step - loss: 1.1119e-07 - mae: 2.7798e-04\n",
      "Epoch 93/300\n",
      "600/600 [==============================] - 0s 814us/step - loss: 1.1117e-07 - mae: 2.7797e-04\n",
      "Epoch 94/300\n",
      "600/600 [==============================] - 0s 693us/step - loss: 1.1118e-07 - mae: 2.7797e-04\n",
      "Epoch 95/300\n",
      "600/600 [==============================] - 0s 714us/step - loss: 1.1116e-07 - mae: 2.7796e-04\n",
      "Epoch 96/300\n",
      "600/600 [==============================] - 0s 688us/step - loss: 1.1116e-07 - mae: 2.7795e-04\n",
      "Epoch 97/300\n",
      "600/600 [==============================] - 0s 691us/step - loss: 1.1115e-07 - mae: 2.7794e-04\n",
      "Epoch 98/300\n",
      "600/600 [==============================] - 0s 689us/step - loss: 1.1114e-07 - mae: 2.7793e-04\n",
      "Epoch 99/300\n",
      "600/600 [==============================] - 0s 686us/step - loss: 1.1114e-07 - mae: 2.7793e-04\n",
      "Epoch 100/300\n",
      "600/600 [==============================] - 0s 718us/step - loss: 1.1113e-07 - mae: 2.7792e-04\n",
      "Epoch 101/300\n",
      "600/600 [==============================] - 0s 766us/step - loss: 1.1112e-07 - mae: 2.7791e-04\n",
      "Epoch 102/300\n",
      "600/600 [==============================] - 1s 837us/step - loss: 1.1112e-07 - mae: 2.7790e-04\n",
      "Epoch 103/300\n",
      "600/600 [==============================] - 1s 842us/step - loss: 1.1111e-07 - mae: 2.7790e-04\n",
      "Epoch 104/300\n",
      "600/600 [==============================] - 0s 813us/step - loss: 1.1110e-07 - mae: 2.7789e-04\n",
      "Epoch 105/300\n",
      "600/600 [==============================] - 0s 761us/step - loss: 1.1110e-07 - mae: 2.7788e-04\n",
      "Epoch 106/300\n",
      "600/600 [==============================] - 1s 894us/step - loss: 1.1109e-07 - mae: 2.7788e-04\n",
      "Epoch 107/300\n",
      "600/600 [==============================] - 0s 723us/step - loss: 1.1108e-07 - mae: 2.7786e-04\n",
      "Epoch 108/300\n",
      "600/600 [==============================] - 0s 754us/step - loss: 1.1108e-07 - mae: 2.7786e-04\n",
      "Epoch 109/300\n",
      "600/600 [==============================] - 0s 711us/step - loss: 1.1106e-07 - mae: 2.7785e-04\n",
      "Epoch 110/300\n",
      "600/600 [==============================] - 0s 723us/step - loss: 1.1106e-07 - mae: 2.7785e-04\n",
      "Epoch 111/300\n",
      "600/600 [==============================] - 0s 696us/step - loss: 1.1105e-07 - mae: 2.7784e-04\n",
      "Epoch 112/300\n",
      "600/600 [==============================] - 0s 716us/step - loss: 1.1105e-07 - mae: 2.7783e-04\n",
      "Epoch 113/300\n",
      "600/600 [==============================] - 0s 713us/step - loss: 1.1103e-07 - mae: 2.7782e-04\n",
      "Epoch 114/300\n",
      "600/600 [==============================] - 0s 703us/step - loss: 1.1104e-07 - mae: 2.7781e-04\n",
      "Epoch 115/300\n",
      "600/600 [==============================] - 0s 711us/step - loss: 1.1103e-07 - mae: 2.7780e-04\n",
      "Epoch 116/300\n",
      "600/600 [==============================] - 0s 716us/step - loss: 1.1102e-07 - mae: 2.7780e-04\n",
      "Epoch 117/300\n",
      "600/600 [==============================] - 0s 688us/step - loss: 1.1101e-07 - mae: 2.7779e-04\n",
      "Epoch 118/300\n",
      "600/600 [==============================] - 0s 714us/step - loss: 1.1101e-07 - mae: 2.7778e-04\n",
      "Epoch 119/300\n",
      "600/600 [==============================] - 0s 696us/step - loss: 1.1100e-07 - mae: 2.7778e-04\n",
      "Epoch 120/300\n",
      "600/600 [==============================] - 0s 691us/step - loss: 1.1099e-07 - mae: 2.7777e-04\n",
      "Epoch 121/300\n",
      "600/600 [==============================] - 0s 708us/step - loss: 1.1098e-07 - mae: 2.7775e-04\n",
      "Epoch 122/300\n",
      "600/600 [==============================] - 0s 701us/step - loss: 1.1098e-07 - mae: 2.7775e-04\n",
      "Epoch 123/300\n",
      "600/600 [==============================] - 0s 693us/step - loss: 1.1097e-07 - mae: 2.7774e-04\n",
      "Epoch 124/300\n",
      "600/600 [==============================] - 0s 691us/step - loss: 1.1097e-07 - mae: 2.7773e-04\n",
      "Epoch 125/300\n",
      "600/600 [==============================] - 0s 718us/step - loss: 1.1096e-07 - mae: 2.7773e-04\n",
      "Epoch 126/300\n",
      "600/600 [==============================] - 0s 694us/step - loss: 1.1095e-07 - mae: 2.7772e-04\n",
      "Epoch 127/300\n",
      "600/600 [==============================] - 0s 716us/step - loss: 1.1095e-07 - mae: 2.7771e-04\n",
      "Epoch 128/300\n",
      "600/600 [==============================] - 0s 674us/step - loss: 1.1094e-07 - mae: 2.7771e-04\n",
      "Epoch 129/300\n",
      "600/600 [==============================] - 0s 704us/step - loss: 1.1093e-07 - mae: 2.7770e-04\n",
      "Epoch 130/300\n",
      "600/600 [==============================] - 0s 718us/step - loss: 1.1093e-07 - mae: 2.7770e-04\n",
      "Epoch 131/300\n",
      "600/600 [==============================] - 1s 891us/step - loss: 1.1092e-07 - mae: 2.7769e-04\n",
      "Epoch 132/300\n",
      "600/600 [==============================] - 0s 754us/step - loss: 1.1091e-07 - mae: 2.7767e-04\n",
      "Epoch 133/300\n",
      "600/600 [==============================] - 0s 782us/step - loss: 1.1091e-07 - mae: 2.7767e-04\n",
      "Epoch 134/300\n",
      "600/600 [==============================] - 0s 819us/step - loss: 1.1090e-07 - mae: 2.7766e-04\n",
      "Epoch 135/300\n",
      "600/600 [==============================] - 0s 796us/step - loss: 1.1089e-07 - mae: 2.7765e-04\n",
      "Epoch 136/300\n",
      "600/600 [==============================] - 1s 854us/step - loss: 1.1089e-07 - mae: 2.7765e-04\n",
      "Epoch 137/300\n",
      "600/600 [==============================] - 0s 761us/step - loss: 1.1088e-07 - mae: 2.7764e-04\n",
      "Epoch 138/300\n",
      "600/600 [==============================] - 0s 799us/step - loss: 1.1088e-07 - mae: 2.7764e-04\n",
      "Epoch 139/300\n",
      "600/600 [==============================] - 0s 738us/step - loss: 1.1087e-07 - mae: 2.7763e-04\n",
      "Epoch 140/300\n",
      "600/600 [==============================] - 0s 746us/step - loss: 1.1086e-07 - mae: 2.7762e-04\n",
      "Epoch 141/300\n",
      "600/600 [==============================] - 0s 754us/step - loss: 1.1085e-07 - mae: 2.7761e-04\n",
      "Epoch 142/300\n",
      "600/600 [==============================] - 0s 808us/step - loss: 1.1084e-07 - mae: 2.7760e-04\n",
      "Epoch 143/300\n",
      "600/600 [==============================] - 0s 733us/step - loss: 1.1084e-07 - mae: 2.7760e-04\n",
      "Epoch 144/300\n",
      "600/600 [==============================] - 0s 724us/step - loss: 1.1084e-07 - mae: 2.7758e-04\n",
      "Epoch 145/300\n",
      "600/600 [==============================] - 0s 731us/step - loss: 1.1083e-07 - mae: 2.7758e-04\n",
      "Epoch 146/300\n",
      "600/600 [==============================] - 0s 721us/step - loss: 1.1082e-07 - mae: 2.7757e-04\n",
      "Epoch 147/300\n",
      "600/600 [==============================] - 0s 718us/step - loss: 1.1081e-07 - mae: 2.7757e-04\n",
      "Epoch 148/300\n",
      "600/600 [==============================] - 0s 733us/step - loss: 1.1082e-07 - mae: 2.7756e-04\n",
      "Epoch 149/300\n",
      "600/600 [==============================] - 0s 733us/step - loss: 1.1080e-07 - mae: 2.7755e-04\n",
      "Epoch 150/300\n",
      "600/600 [==============================] - 0s 721us/step - loss: 1.1079e-07 - mae: 2.7754e-04\n",
      "Epoch 151/300\n",
      "600/600 [==============================] - 0s 728us/step - loss: 1.1079e-07 - mae: 2.7754e-04\n",
      "Epoch 152/300\n",
      "600/600 [==============================] - 0s 734us/step - loss: 1.1078e-07 - mae: 2.7753e-04\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 796us/step - loss: 1.1078e-07 - mae: 2.7753e-04\n",
      "Epoch 154/300\n",
      "600/600 [==============================] - 1s 846us/step - loss: 1.1077e-07 - mae: 2.7751e-04\n",
      "Epoch 155/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1077e-07 - mae: 2.7751e-04\n",
      "Epoch 156/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1076e-07 - mae: 2.7750e-04\n",
      "Epoch 157/300\n",
      "600/600 [==============================] - 1s 969us/step - loss: 1.1075e-07 - mae: 2.7749e-04\n",
      "Epoch 158/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1075e-07 - mae: 2.7749e-04\n",
      "Epoch 159/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1074e-07 - mae: 2.7748e-04\n",
      "Epoch 160/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1073e-07 - mae: 2.7747e-04A: 0s - loss: 1.0774e-07 - mae: 2.741\n",
      "Epoch 161/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1073e-07 - mae: 2.7747e-04\n",
      "Epoch 162/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1072e-07 - mae: 2.7746e-04\n",
      "Epoch 163/300\n",
      "600/600 [==============================] - 0s 794us/step - loss: 1.1072e-07 - mae: 2.7746e-04\n",
      "Epoch 164/300\n",
      "600/600 [==============================] - 1s 834us/step - loss: 1.1071e-07 - mae: 2.7744e-04\n",
      "Epoch 165/300\n",
      "600/600 [==============================] - 1s 982us/step - loss: 1.1070e-07 - mae: 2.7744e-04\n",
      "Epoch 166/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1069e-07 - mae: 2.7743e-04\n",
      "Epoch 167/300\n",
      "600/600 [==============================] - 1s 886us/step - loss: 1.1069e-07 - mae: 2.7742e-04\n",
      "Epoch 168/300\n",
      "600/600 [==============================] - 0s 753us/step - loss: 1.1068e-07 - mae: 2.7742e-04\n",
      "Epoch 169/300\n",
      "600/600 [==============================] - 1s 842us/step - loss: 1.1067e-07 - mae: 2.7741e-04\n",
      "Epoch 170/300\n",
      "600/600 [==============================] - 0s 759us/step - loss: 1.1067e-07 - mae: 2.7740e-04\n",
      "Epoch 171/300\n",
      "600/600 [==============================] - 0s 740us/step - loss: 1.1066e-07 - mae: 2.7740e-04\n",
      "Epoch 172/300\n",
      "600/600 [==============================] - 0s 776us/step - loss: 1.1065e-07 - mae: 2.7739e-04\n",
      "Epoch 173/300\n",
      "600/600 [==============================] - 0s 788us/step - loss: 1.1065e-07 - mae: 2.7738e-04\n",
      "Epoch 174/300\n",
      "600/600 [==============================] - 0s 776us/step - loss: 1.1064e-07 - mae: 2.7737e-04\n",
      "Epoch 175/300\n",
      "600/600 [==============================] - 0s 753us/step - loss: 1.1063e-07 - mae: 2.7737e-04\n",
      "Epoch 176/300\n",
      "600/600 [==============================] - 0s 764us/step - loss: 1.1063e-07 - mae: 2.7736e-04\n",
      "Epoch 177/300\n",
      "600/600 [==============================] - 0s 759us/step - loss: 1.1062e-07 - mae: 2.7735e-04\n",
      "Epoch 178/300\n",
      "600/600 [==============================] - 0s 733us/step - loss: 1.1061e-07 - mae: 2.7735e-04\n",
      "Epoch 179/300\n",
      "600/600 [==============================] - 0s 779us/step - loss: 1.1061e-07 - mae: 2.7734e-04\n",
      "Epoch 180/300\n",
      "600/600 [==============================] - 0s 741us/step - loss: 1.1060e-07 - mae: 2.7733e-04\n",
      "Epoch 181/300\n",
      "600/600 [==============================] - 0s 749us/step - loss: 1.1060e-07 - mae: 2.7733e-04\n",
      "Epoch 182/300\n",
      "600/600 [==============================] - 0s 738us/step - loss: 1.1059e-07 - mae: 2.7732e-04\n",
      "Epoch 183/300\n",
      "600/600 [==============================] - 0s 760us/step - loss: 1.1059e-07 - mae: 2.7731e-04\n",
      "Epoch 184/300\n",
      "600/600 [==============================] - 0s 766us/step - loss: 1.1058e-07 - mae: 2.7731e-04\n",
      "Epoch 185/300\n",
      "600/600 [==============================] - 0s 747us/step - loss: 1.1057e-07 - mae: 2.7730e-04\n",
      "Epoch 186/300\n",
      "600/600 [==============================] - 0s 744us/step - loss: 1.1057e-07 - mae: 2.7729e-04\n",
      "Epoch 187/300\n",
      "600/600 [==============================] - 0s 741us/step - loss: 1.1056e-07 - mae: 2.7729e-04\n",
      "Epoch 188/300\n",
      "600/600 [==============================] - 0s 806us/step - loss: 1.1055e-07 - mae: 2.7728e-04\n",
      "Epoch 189/300\n",
      "600/600 [==============================] - 0s 746us/step - loss: 1.1055e-07 - mae: 2.7727e-04\n",
      "Epoch 190/300\n",
      "600/600 [==============================] - 0s 736us/step - loss: 1.1054e-07 - mae: 2.7727e-04\n",
      "Epoch 191/300\n",
      "600/600 [==============================] - 0s 788us/step - loss: 1.1054e-07 - mae: 2.7726e-04\n",
      "Epoch 192/300\n",
      "600/600 [==============================] - 1s 892us/step - loss: 1.1053e-07 - mae: 2.7725e-04\n",
      "Epoch 193/300\n",
      "600/600 [==============================] - 0s 779us/step - loss: 1.1052e-07 - mae: 2.7724e-04\n",
      "Epoch 194/300\n",
      "600/600 [==============================] - 0s 791us/step - loss: 1.1052e-07 - mae: 2.7724e-04\n",
      "Epoch 195/300\n",
      "600/600 [==============================] - 0s 758us/step - loss: 1.1051e-07 - mae: 2.7723e-04\n",
      "Epoch 196/300\n",
      "600/600 [==============================] - 0s 756us/step - loss: 1.1050e-07 - mae: 2.7722e-04\n",
      "Epoch 197/300\n",
      "600/600 [==============================] - 0s 801us/step - loss: 1.1050e-07 - mae: 2.7721e-04\n",
      "Epoch 198/300\n",
      "600/600 [==============================] - 0s 758us/step - loss: 1.1049e-07 - mae: 2.7720e-04\n",
      "Epoch 199/300\n",
      "600/600 [==============================] - 0s 786us/step - loss: 1.1049e-07 - mae: 2.7721e-04\n",
      "Epoch 200/300\n",
      "600/600 [==============================] - 0s 768us/step - loss: 1.1048e-07 - mae: 2.7720e-04\n",
      "Epoch 201/300\n",
      "600/600 [==============================] - 1s 947us/step - loss: 1.1048e-07 - mae: 2.7718e-04\n",
      "Epoch 202/300\n",
      "600/600 [==============================] - 1s 842us/step - loss: 1.1047e-07 - mae: 2.7718e-04\n",
      "Epoch 203/300\n",
      "600/600 [==============================] - 1s 836us/step - loss: 1.1046e-07 - mae: 2.7718e-04\n",
      "Epoch 204/300\n",
      "600/600 [==============================] - 1s 864us/step - loss: 1.1046e-07 - mae: 2.7717e-04\n",
      "Epoch 205/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1045e-07 - mae: 2.7716e-04\n",
      "Epoch 206/300\n",
      "600/600 [==============================] - 1s 919us/step - loss: 1.1045e-07 - mae: 2.7716e-04\n",
      "Epoch 207/300\n",
      "600/600 [==============================] - 1s 883us/step - loss: 1.1044e-07 - mae: 2.7715e-04\n",
      "Epoch 208/300\n",
      "600/600 [==============================] - 0s 781us/step - loss: 1.1043e-07 - mae: 2.7714e-04\n",
      "Epoch 209/300\n",
      "600/600 [==============================] - 0s 766us/step - loss: 1.1043e-07 - mae: 2.7714e-04\n",
      "Epoch 210/300\n",
      "600/600 [==============================] - 0s 759us/step - loss: 1.1042e-07 - mae: 2.7713e-04\n",
      "Epoch 211/300\n",
      "600/600 [==============================] - 1s 859us/step - loss: 1.1041e-07 - mae: 2.7712e-04\n",
      "Epoch 212/300\n",
      "600/600 [==============================] - 0s 824us/step - loss: 1.1041e-07 - mae: 2.7712e-04\n",
      "Epoch 213/300\n",
      "600/600 [==============================] - 1s 887us/step - loss: 1.1040e-07 - mae: 2.7711e-04\n",
      "Epoch 214/300\n",
      "600/600 [==============================] - 0s 810us/step - loss: 1.1040e-07 - mae: 2.7710e-04\n",
      "Epoch 215/300\n",
      "600/600 [==============================] - 0s 763us/step - loss: 1.1039e-07 - mae: 2.7709e-04\n",
      "Epoch 216/300\n",
      "600/600 [==============================] - 0s 769us/step - loss: 1.1038e-07 - mae: 2.7709e-04\n",
      "Epoch 217/300\n",
      "600/600 [==============================] - 1s 844us/step - loss: 1.1038e-07 - mae: 2.7708e-04\n",
      "Epoch 218/300\n",
      "600/600 [==============================] - 0s 779us/step - loss: 1.1037e-07 - mae: 2.7707e-04\n",
      "Epoch 219/300\n",
      "600/600 [==============================] - 0s 793us/step - loss: 1.1036e-07 - mae: 2.7707e-04\n",
      "Epoch 220/300\n",
      "600/600 [==============================] - 0s 819us/step - loss: 1.1036e-07 - mae: 2.7706e-04\n",
      "Epoch 221/300\n",
      "600/600 [==============================] - 0s 831us/step - loss: 1.1035e-07 - mae: 2.7704e-04\n",
      "Epoch 222/300\n",
      "600/600 [==============================] - 0s 786us/step - loss: 1.1035e-07 - mae: 2.7705e-04\n",
      "Epoch 223/300\n",
      "600/600 [==============================] - 0s 768us/step - loss: 1.1035e-07 - mae: 2.7705e-04\n",
      "Epoch 224/300\n",
      "600/600 [==============================] - 1s 846us/step - loss: 1.1033e-07 - mae: 2.7703e-04\n",
      "Epoch 225/300\n",
      "600/600 [==============================] - 1s 888us/step - loss: 1.1033e-07 - mae: 2.7703e-04\n",
      "Epoch 226/300\n",
      "600/600 [==============================] - 0s 828us/step - loss: 1.1032e-07 - mae: 2.7702e-04\n",
      "Epoch 227/300\n",
      "600/600 [==============================] - 0s 783us/step - loss: 1.1032e-07 - mae: 2.7701e-04\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 774us/step - loss: 1.1031e-07 - mae: 2.7700e-04\n",
      "Epoch 229/300\n",
      "600/600 [==============================] - 0s 773us/step - loss: 1.1030e-07 - mae: 2.7699e-04\n",
      "Epoch 230/300\n",
      "600/600 [==============================] - 1s 851us/step - loss: 1.1030e-07 - mae: 2.7699e-04\n",
      "Epoch 231/300\n",
      "600/600 [==============================] - 0s 796us/step - loss: 1.1030e-07 - mae: 2.7699e-04\n",
      "Epoch 232/300\n",
      "600/600 [==============================] - 0s 778us/step - loss: 1.1029e-07 - mae: 2.7698e-04\n",
      "Epoch 233/300\n",
      "600/600 [==============================] - 0s 789us/step - loss: 1.1028e-07 - mae: 2.7697e-04\n",
      "Epoch 234/300\n",
      "600/600 [==============================] - 0s 794us/step - loss: 1.1028e-07 - mae: 2.7696e-04\n",
      "Epoch 235/300\n",
      "600/600 [==============================] - 0s 812us/step - loss: 1.1027e-07 - mae: 2.7695e-04\n",
      "Epoch 236/300\n",
      "600/600 [==============================] - 0s 815us/step - loss: 1.1026e-07 - mae: 2.7695e-04\n",
      "Epoch 237/300\n",
      "600/600 [==============================] - 0s 804us/step - loss: 1.1026e-07 - mae: 2.7694e-04\n",
      "Epoch 238/300\n",
      "600/600 [==============================] - 0s 814us/step - loss: 1.1025e-07 - mae: 2.7693e-04\n",
      "Epoch 239/300\n",
      "600/600 [==============================] - 1s 871us/step - loss: 1.1025e-07 - mae: 2.7693e-04\n",
      "Epoch 240/300\n",
      "600/600 [==============================] - 1s 841us/step - loss: 1.1024e-07 - mae: 2.7692e-04\n",
      "Epoch 241/300\n",
      "600/600 [==============================] - 0s 826us/step - loss: 1.1023e-07 - mae: 2.7691e-04\n",
      "Epoch 242/300\n",
      "600/600 [==============================] - 1s 864us/step - loss: 1.1023e-07 - mae: 2.7690e-04\n",
      "Epoch 243/300\n",
      "600/600 [==============================] - 0s 822us/step - loss: 1.1022e-07 - mae: 2.7690e-04\n",
      "Epoch 244/300\n",
      "600/600 [==============================] - 0s 806us/step - loss: 1.1022e-07 - mae: 2.7689e-04\n",
      "Epoch 245/300\n",
      "600/600 [==============================] - 1s 880us/step - loss: 1.1021e-07 - mae: 2.7688e-04\n",
      "Epoch 246/300\n",
      "600/600 [==============================] - 0s 824us/step - loss: 1.1021e-07 - mae: 2.7688e-04\n",
      "Epoch 247/300\n",
      "600/600 [==============================] - 0s 803us/step - loss: 1.1020e-07 - mae: 2.7687e-04\n",
      "Epoch 248/300\n",
      "600/600 [==============================] - 1s 846us/step - loss: 1.1019e-07 - mae: 2.7686e-04\n",
      "Epoch 249/300\n",
      "600/600 [==============================] - 0s 804us/step - loss: 1.1018e-07 - mae: 2.7685e-04\n",
      "Epoch 250/300\n",
      "600/600 [==============================] - 1s 898us/step - loss: 1.1018e-07 - mae: 2.7685e-04\n",
      "Epoch 251/300\n",
      "600/600 [==============================] - 1s 851us/step - loss: 1.1017e-07 - mae: 2.7684e-04\n",
      "Epoch 252/300\n",
      "600/600 [==============================] - 0s 818us/step - loss: 1.1017e-07 - mae: 2.7683e-04\n",
      "Epoch 253/300\n",
      "600/600 [==============================] - 1s 881us/step - loss: 1.1016e-07 - mae: 2.7683e-04\n",
      "Epoch 254/300\n",
      "600/600 [==============================] - 1s 836us/step - loss: 1.1015e-07 - mae: 2.7682e-04\n",
      "Epoch 255/300\n",
      "600/600 [==============================] - 1s 913us/step - loss: 1.1015e-07 - mae: 2.7682e-04\n",
      "Epoch 256/300\n",
      "600/600 [==============================] - 1s 929us/step - loss: 1.1014e-07 - mae: 2.7680e-04\n",
      "Epoch 257/300\n",
      "600/600 [==============================] - 1s 873us/step - loss: 1.1014e-07 - mae: 2.7679e-04\n",
      "Epoch 258/300\n",
      "600/600 [==============================] - 1s 962us/step - loss: 1.1013e-07 - mae: 2.7679e-04\n",
      "Epoch 259/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1013e-07 - mae: 2.7678e-04\n",
      "Epoch 260/300\n",
      "600/600 [==============================] - 1s 884us/step - loss: 1.1012e-07 - mae: 2.7678e-04\n",
      "Epoch 261/300\n",
      "600/600 [==============================] - 1s 837us/step - loss: 1.1011e-07 - mae: 2.7677e-04\n",
      "Epoch 262/300\n",
      "600/600 [==============================] - 1s 901us/step - loss: 1.1011e-07 - mae: 2.7676e-04\n",
      "Epoch 263/300\n",
      "600/600 [==============================] - 1s 954us/step - loss: 1.1010e-07 - mae: 2.7676e-04\n",
      "Epoch 264/300\n",
      "600/600 [==============================] - 1s 896us/step - loss: 1.1010e-07 - mae: 2.7675e-04\n",
      "Epoch 265/300\n",
      "600/600 [==============================] - 1s 873us/step - loss: 1.1009e-07 - mae: 2.7675e-04\n",
      "Epoch 266/300\n",
      "600/600 [==============================] - 1s 923us/step - loss: 1.1008e-07 - mae: 2.7673e-04\n",
      "Epoch 267/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1008e-07 - mae: 2.7673e-04\n",
      "Epoch 268/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1007e-07 - mae: 2.7672e-04\n",
      "Epoch 269/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1007e-07 - mae: 2.7671e-04\n",
      "Epoch 270/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1006e-07 - mae: 2.7671e-04\n",
      "Epoch 271/300\n",
      "600/600 [==============================] - 1s 971us/step - loss: 1.1005e-07 - mae: 2.7670e-04\n",
      "Epoch 272/300\n",
      "600/600 [==============================] - 1s 907us/step - loss: 1.1005e-07 - mae: 2.7669e-04\n",
      "Epoch 273/300\n",
      "600/600 [==============================] - 1s 859us/step - loss: 1.1004e-07 - mae: 2.7669e-04\n",
      "Epoch 274/300\n",
      "600/600 [==============================] - 1s 846us/step - loss: 1.1004e-07 - mae: 2.7668e-04\n",
      "Epoch 275/300\n",
      "600/600 [==============================] - 1s 858us/step - loss: 1.1003e-07 - mae: 2.7668e-04\n",
      "Epoch 276/300\n",
      "600/600 [==============================] - 1s 892us/step - loss: 1.1003e-07 - mae: 2.7667e-04\n",
      "Epoch 277/300\n",
      "600/600 [==============================] - 1s 907us/step - loss: 1.1002e-07 - mae: 2.7666e-04\n",
      "Epoch 278/300\n",
      "600/600 [==============================] - 1s 885us/step - loss: 1.1001e-07 - mae: 2.7666e-04\n",
      "Epoch 279/300\n",
      "600/600 [==============================] - 1s 861us/step - loss: 1.1001e-07 - mae: 2.7665e-04\n",
      "Epoch 280/300\n",
      "600/600 [==============================] - 1s 849us/step - loss: 1.1000e-07 - mae: 2.7664e-04\n",
      "Epoch 281/300\n",
      "600/600 [==============================] - 1s 888us/step - loss: 1.0999e-07 - mae: 2.7663e-04\n",
      "Epoch 282/300\n",
      "600/600 [==============================] - 1s 872us/step - loss: 1.0999e-07 - mae: 2.7663e-04\n",
      "Epoch 283/300\n",
      "600/600 [==============================] - 1s 889us/step - loss: 1.0998e-07 - mae: 2.7663e-04\n",
      "Epoch 284/300\n",
      "600/600 [==============================] - 1s 904us/step - loss: 1.0998e-07 - mae: 2.7663e-04\n",
      "Epoch 285/300\n",
      "600/600 [==============================] - 1s 920us/step - loss: 1.0997e-07 - mae: 2.7660e-04\n",
      "Epoch 286/300\n",
      "600/600 [==============================] - 1s 904us/step - loss: 1.0997e-07 - mae: 2.7660e-04\n",
      "Epoch 287/300\n",
      "600/600 [==============================] - 1s 884us/step - loss: 1.0996e-07 - mae: 2.7660e-04\n",
      "Epoch 288/300\n",
      "600/600 [==============================] - 1s 880us/step - loss: 1.0995e-07 - mae: 2.7659e-04\n",
      "Epoch 289/300\n",
      "600/600 [==============================] - 1s 865us/step - loss: 1.0995e-07 - mae: 2.7659e-04\n",
      "Epoch 290/300\n",
      "600/600 [==============================] - 1s 877us/step - loss: 1.0994e-07 - mae: 2.7658e-04\n",
      "Epoch 291/300\n",
      "600/600 [==============================] - 1s 881us/step - loss: 1.0994e-07 - mae: 2.7657e-04\n",
      "Epoch 292/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.0994e-07 - mae: 2.7657e-04\n",
      "Epoch 293/300\n",
      "600/600 [==============================] - 1s 986us/step - loss: 1.0993e-07 - mae: 2.7657e-04\n",
      "Epoch 294/300\n",
      "600/600 [==============================] - 1s 949us/step - loss: 1.0992e-07 - mae: 2.7655e-04\n",
      "Epoch 295/300\n",
      "600/600 [==============================] - 1s 891us/step - loss: 1.0992e-07 - mae: 2.7655e-04\n",
      "Epoch 296/300\n",
      "600/600 [==============================] - 1s 858us/step - loss: 1.0991e-07 - mae: 2.7654e-04\n",
      "Epoch 297/300\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.0990e-07 - mae: 2.7654e-04\n",
      "Epoch 298/300\n",
      "600/600 [==============================] - 1s 847us/step - loss: 1.0990e-07 - mae: 2.7653e-04\n",
      "Epoch 299/300\n",
      "600/600 [==============================] - 1s 839us/step - loss: 1.0989e-07 - mae: 2.7652e-04\n",
      "Epoch 300/300\n",
      "600/600 [==============================] - 0s 831us/step - loss: 1.0989e-07 - mae: 2.7652e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x260bbf39220>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=300, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f899e84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 726us/step - loss: 1.1766e-07 - mae: 2.8428e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1765813923148016e-07, 0.00028427530196495354]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_input=1):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(128, activation='relu',input_dim=num_input))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(optimizer='Adagrad', loss='mae', metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_input=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_input=13)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.25, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc63fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "721e1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train) # 정답이 없는 데이터 predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97a83ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "r_squared = r2_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2f9fc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_Absolute_Error: 0.0002842748269547531\n",
      "Mean_Squared_Error : 1.1765748035880374e-07\n",
      "Root_Mean_Squared_Error : 0.0003430123618163108\n",
      "R_Square_value : 0.9999994572829146\n"
     ]
    }
   ],
   "source": [
    "print('Mean_Absolute_Error:', mae)\n",
    "print('Mean_Squared_Error :' ,mse)\n",
    "print('Root_Mean_Squared_Error :' ,np.sqrt(mse))\n",
    "print('R_Square_value :',r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13b4281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('./1번/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38be1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "       'feature_5', 'feature_6', 'feature_7', 'feature_9',\n",
    "       'feature_10', 'feature_12', 'feature_13', 'feature_14']]\n",
    "#test_df = np.log1p(test_df)\n",
    "result_df = np.log1p(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a92e3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = minMaxScaler.transform(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b88d067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = standardScaler.transform(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = robustScaler.transform(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c65e6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = model.predict(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3fb241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7960086 ],\n",
       "       [0.35434896],\n",
       "       [0.45312196],\n",
       "       ...,\n",
       "       [0.4854979 ],\n",
       "       [0.2764659 ],\n",
       "       [0.2880633 ]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df9fad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_result, columns=['target']).to_csv('./1번/result_d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ffe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_input=81)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=200, validation_split=0.25, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38086bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curve(total_epoch=10, start=1):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(range(start, total_epoch +1), history.history['loss'][start-1:total_epoch], label='Train')\n",
    "    plt.plot(range(start, total_epoch +1), history.history['val_loss'][start-1:total_epoch], label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mse')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curve(total_epoch=200, start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009669da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_loss_curve(total_epoch=200, start=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b407535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean_Absolute_Error:', mae)\n",
    "print('Mean_Squared_Error :' ,mse)\n",
    "print('Root_Mean_Squared_Error :' ,np.sqrt(mse))\n",
    "print('R_Square_value :',r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('./2번/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2985ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = model.predict(result_df)\n",
    "y_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_result, columns=['target']).to_csv('./2번/result_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd9fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c480f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261a160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14647580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_test = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ce134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.001).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77400d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"훈련 세트 점수: {:.5f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.5f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4dee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7c3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean_Absolute_Error:', mae)\n",
    "print('Mean_Squared_Error :' ,mse)\n",
    "print('Root_Mean_Squared_Error :' ,np.sqrt(mse))\n",
    "print('R_Square_value :',r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bcabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./2번/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
    "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
    "       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n",
    "       'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24',\n",
    "       'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29',\n",
    "       'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34',\n",
    "       'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39',\n",
    "       'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44',\n",
    "       'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49',\n",
    "       'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54',\n",
    "       'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59',\n",
    "       'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64',\n",
    "       'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69',\n",
    "       'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74',\n",
    "       'feature_75', 'feature_76', 'feature_77', 'feature_78', 'feature_79',\n",
    "       'feature_80']]\n",
    "test_df = mms.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e259c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = ridge.predict(test_df)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_result, columns=['target']).to_csv('./2번/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statsmodels.api modeling 활용\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = X_train\n",
    "X_train_sm = sm.add_constant(X_train_sm)\n",
    "\n",
    "lm_1 = sm.OLS(y_train,X_train_sm).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e208733",
   "metadata": {},
   "source": [
    "## Performing Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb4d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegression lr(Creating LinearRegression Object)\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the training data\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2330abc",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the intercept(절편)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1abe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient(상관계수)\n",
    "coeff_df = pd.DataFrame(lm.coef_, X_test.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcaf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52488e4f",
   "metadata": {},
   "source": [
    "## Calculating Evalutaiton MSE, R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7652dfd",
   "metadata": {},
   "source": [
    "## Importing and Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3e6ba",
   "metadata": {},
   "source": [
    "## Importing and Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f8914",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Mean_Absolute_Error:', mae)\n",
    "print('Mean_Squared_Error :' ,mse)\n",
    "print('Root_Mean_Squared_Error :' ,np.sqrt(mse))\n",
    "print('R_Square_value :',r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2dc09",
   "metadata": {},
   "source": [
    "## - Acutal vs Prediction 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual vs Predicted\n",
    "c = [i for i in range(1,2057,1)]\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "plt.plot(c,y_test, color=\"blue\", linewidth=0.2, linestyle=\"-\")\n",
    "plt.plot(c,y_pred, color=\"red\",  linewidth=0.2, linestyle=\"-\")\n",
    "fig.suptitle('Actual and Predicted', fontsize=20)              # Plot heading \n",
    "plt.xlabel('Index', fontsize=18)                               # X-label\n",
    "plt.ylabel('target', fontsize=16)                               # Y-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_200 = y_test.iloc[0:200]\n",
    "y_pred_200 = y_pred[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08788374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual vs Predicted\n",
    "c = [i for i in range(1,201,1)]\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "plt.plot(c,y_test_200, color=\"blue\", linewidth=0.5, linestyle=\"-\")\n",
    "plt.plot(c,y_pred_200, color=\"red\",  linewidth=0.5, linestyle=\"-\")\n",
    "fig.suptitle('Actual and Predicted', fontsize=20)              # Plot heading \n",
    "plt.xlabel('Index', fontsize=18)                               # X-label\n",
    "plt.ylabel('target', fontsize=16)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e6604",
   "metadata": {},
   "source": [
    "### 최소-최대 스케일링(min-max scaling):\n",
    "\n",
    "$x^{(i)}_{norm} = \\dfrac{x^{(i)}-x_{min}}{x_{max}-x_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e23efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c3f575",
   "metadata": {},
   "source": [
    "## 표준화(standardization):\n",
    "\n",
    "$x^{(i)}_{std} = \\dfrac{x^{(i)}-\\mu_x}{\\sigma_x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f36099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "X_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f5b0c",
   "metadata": {},
   "source": [
    "### Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d690d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rbs = RobustScaler()\n",
    "X_train_robust = rbs.fit_transform(X_train)\n",
    "X_test_robust = rbs.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b86e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_norm = LinearRegression()\n",
    "lm_norm.fit(X_train_std,y_train)\n",
    "lm_std = LinearRegression()\n",
    "lm_std.fit(X_train_std,y_train)\n",
    "lm_robust = LinearRegression()\n",
    "lm_robust.fit(X_train_robust,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d858928",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_norm = lm_norm.predict(X_test_norm)\n",
    "y_pred_std = lm_std.predict(X_test_std)\n",
    "y_pred_robust = lm_robust.predict(X_test_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ea6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_norm = mean_squared_error(y_test, y_pred_norm)\n",
    "mse_std = mean_squared_error(y_test, y_pred_std)\n",
    "mse_robust = mean_squared_error(y_test, y_pred_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mse_norm))\n",
    "print(np.sqrt(mse_std))\n",
    "print(np.sqrt(mse_robust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906e31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ea5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ebb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b0c3018",
   "metadata": {},
   "source": [
    "## trainset전체데이터 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80586e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_result_df = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff585fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fuel_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d73765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature variable to X\n",
    "X_new = fuel_df[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "       'feature_5', 'feature_6', 'feature_7', 'feature_9',\n",
    "       'feature_10', 'feature_12', 'feature_13', 'feature_14']]\n",
    "\n",
    "# response target variable to y\n",
    "y_new = fuel_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_result = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_result.fit(X_new,y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_result = fuel_result_df[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "       'feature_5', 'feature_6', 'feature_7', 'feature_9',\n",
    "       'feature_10', 'feature_12', 'feature_13', 'feature_14']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = lm_result.predict(X_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a16922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = lm.predict(X_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1414a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aedf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = lm_norm.predict(X_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57623b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22ed2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf032e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9fc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f84f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9625df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_result_df['target'] = pd.Series(y_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18289a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_result_df['target'].to_csv('dataset/result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8579b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
